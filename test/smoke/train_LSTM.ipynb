{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb6a5d0",
   "metadata": {},
   "source": [
    "# **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d46ee1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import os, pickle\n",
    "from zipfile import ZipFile\n",
    "from warnings import filterwarnings\n",
    "\n",
    "# Machine learning packages\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow import keras\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd9c6ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 50                # Size of array\n",
    "predictionHorizonMax = 12  # Maximum prediction horizon\n",
    "neurons = 64               # Number of neurons in LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6921253",
   "metadata": {},
   "source": [
    "#  **Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3020d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SerieMatriz(timeSerie, predictionHorizonMax, window):\n",
    "  timeSerie = np.squeeze(timeSerie)\n",
    "\n",
    "  X = np.zeros([len(timeSerie)-predictionHorizonMax-window+1, window])\n",
    "  y = np.zeros([len(timeSerie)-predictionHorizonMax-window+1, predictionHorizonMax])\n",
    "  for i in range(X.shape[0]):\n",
    "      X[i,:] = timeSerie[i:i+window]\n",
    "      y[i,:] = timeSerie[i+window: i+window+predictionHorizonMax]\n",
    "  \n",
    "  return X, np.squeeze(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bd1023",
   "metadata": {},
   "source": [
    "# **Read datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0665cb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================ open_meteo_la_jagua_del_pilar.csv\n",
      "================================================ open_meteo_san_juan_del_cesar.csv\n",
      "================================================ open_meteo_hatonuevo.csv\n",
      "================================================ open_meteo_riohacha.csv\n",
      "================================================ open_meteo_albania.csv\n",
      "================================================ open_meteo_uribia.csv\n",
      "================================================ open_meteo_manaure.csv\n",
      "================================================ open_meteo_distraccion.csv\n",
      "================================================ open_meteo_el_molino.csv\n",
      "================================================ open_meteo_mingueo.csv\n",
      "================================================ open_meteo_maicao.csv\n",
      "================================================ open_meteo_barrancas.csv\n",
      "================================================ open_meteo_fonseca.csv\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/guane/Documentos/Doctorate/GuajiraSustainableWindBot/data/raw'\n",
    "datasets = os.listdir(path)\n",
    "\n",
    "data = {}\n",
    "for csv_file in datasets:\n",
    "\n",
    "  name = csv_file.split('.')[0]\n",
    "  print(\"======\"*8, csv_file)\n",
    "  \n",
    "  # Read dataset\n",
    "  df = pd.read_csv(path + '/' + csv_file)\n",
    "\n",
    "  timeSerie = df['wind_speed_10m']\n",
    "  time = np.arange(0, len(timeSerie),1)\n",
    "\n",
    "  # Create time series matrix\n",
    "  #X, y = SerieMatriz(timeSerie, predictionHorizonMax, window)\n",
    "\n",
    "  #X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "  #X_train, X_valid, y_train, y_valid = train_test_split(X_, y_, test_size=0.2, random_state=42)\n",
    "\n",
    "  #X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "  #X_valid = np.reshape(X_valid, (X_valid.shape[0], X_valid.shape[1], 1))\n",
    "  #X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63270761",
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
