# Ejemplo: Streamlit ChatBot con Docker y OpenAI

Este ejemplo muestra c√≥mo dockerizar una aplicaci√≥n de Streamlit que usa LangChain con OpenAI para crear un chatbot de pron√≥stico de viento.

## üìã Contenido

- `app_streamlit.py`: Aplicaci√≥n Streamlit con interfaz de chat
- `Dockerfile`: Configuraci√≥n de Docker para la aplicaci√≥n
- `requirements.txt`: Dependencias de Python
- `.dockerignore`: Archivos a excluir del build
- `.env.example`: Plantilla para variables de entorno

## üèóÔ∏è Arquitectura

La aplicaci√≥n usa:
- **Streamlit**: Framework para la interfaz web
- **LangChain**: Para integraci√≥n con modelos LLM
- **OpenAI**: Proveedor de modelos (GPT-3.5-turbo, GPT-4, GPT-4-turbo)

## üì¶ Pre-requisitos

Antes de iniciar, aseg√∫rate de tener instalado:
- **Docker Desktop** (para Mac/Windows) o **Docker Engine** (para Linux)
- **OpenAI API Key** - Obt√©n una en [OpenAI Platform](https://platform.openai.com/api-keys)

### Verificar instalaci√≥n de Docker

```bash
# Verificar que Docker est√° instalado
docker --version
# Output esperado: Docker version 24.x.x, build ...

# Verificar que Docker daemon est√° corriendo
docker ps
# Si funciona, ver√°s una lista de contenedores (puede estar vac√≠a)
```

**‚ö†Ô∏è Si obtienes un error**: Inicia Docker Desktop desde tu aplicaci√≥n y espera a que el √≠cono de Docker en la barra superior est√© activo.

## üöÄ Inicializaci√≥n de Docker - Paso a Paso

### Paso 1: Navegar al directorio del ejemplo

```bash
cd examples/streamlit-docker-openai
```

### Paso 2: Construir la imagen Docker

```bash
docker build -t wind-forecast-app .
```

**¬øQu√© hace esto?**
- Lee el `Dockerfile` y construye una imagen
- Descarga Python 3.11-slim como base
- Instala todas las dependencias de `requirements.txt`
- Copia el c√≥digo de la aplicaci√≥n
- Etiqueta la imagen como `wind-forecast-app`

**Tiempo estimado**: 2-5 minutos (primera vez)

### Paso 3: Ejecutar el contenedor

Tienes dos opciones para pasar tu API key:

#### Opci√≥n A: API Key directamente en el comando

```bash
docker run -d --name streamlit-docker-openai -p 8501:8501 \
  -e OPENAI_API_KEY=sk-tu-api-key-aqui wind-forecast-app
```

#### Opci√≥n B: Usando archivo .env (Recomendado)

```bash
# 1. Crear archivo .env
echo "OPENAI_API_KEY=sk-tu-api-key-aqui" > .env

# 2. Ejecutar con el archivo .env
docker run -d --name streamlit-docker-openai -p 8501:8501 \
  --env-file .env wind-forecast-app
```

**¬øQu√© hace esto?**
- `-d`: Ejecuta el contenedor en segundo plano (detached mode)
- `--name streamlit-docker-openai`: Asigna un nombre personalizado al contenedor
- `-p 8501:8501`: Mapea el puerto 8501 del contenedor al puerto 8501 de tu m√°quina
- `-e` o `--env-file`: Pasa variables de entorno al contenedor
- `wind-forecast-app`: Nombre de la imagen a ejecutar

### Paso 4: Acceder a la aplicaci√≥n

Abre tu navegador en: **http://localhost:8501**

Deber√≠as ver la interfaz de Streamlit con el chatbot listo para usar.

## üõ†Ô∏è Comandos de Gesti√≥n de Docker

### Detener el contenedor

```bash
# Usando el nombre del contenedor
docker stop streamlit-docker-openai

# O usando el ID
docker ps                        # Ver ID del contenedor
docker stop <container_id>
```

### Ver logs

```bash
# Ver logs completos
docker logs streamlit-docker-openai

# Seguir logs en tiempo real
docker logs -f streamlit-docker-openai

# Ver √∫ltimas 50 l√≠neas
docker logs --tail 50 streamlit-docker-openai
```

### Reiniciar el contenedor

```bash
# Reiniciar contenedor existente
docker restart streamlit-docker-openai

# Iniciar contenedor detenido
docker start streamlit-docker-openai
```

### Ver contenedores e im√°genes

```bash
# Ver contenedores corriendo
docker ps

# Ver todos los contenedores (incluso detenidos)
docker ps -a

# Ver im√°genes Docker
docker images

# Ver uso de espacio
docker system df
```

### Limpiar recursos Docker

```bash
# Detener y eliminar el contenedor
docker rm -f streamlit-docker-openai

# Eliminar solo si est√° detenido
docker rm streamlit-docker-openai

# Eliminar imagen
docker rmi wind-forecast-app

# Eliminar todos los contenedores detenidos
docker container prune

# Eliminar im√°genes sin usar
docker image prune

# Limpieza completa (¬°cuidado!)
docker system prune -a
```

### Reconstruir la imagen (despu√©s de cambios en el c√≥digo)

```bash
# Reconstruir con cach√©
docker build -t wind-forecast-app .

# Reconstruir sin cach√© (fuerza descarga de todo)
docker build --no-cache -t wind-forecast-app .
```

## üîç Troubleshooting

### Error: "Cannot connect to Docker daemon"

**Problema**: Docker no est√° corriendo.

**Soluci√≥n**:
```bash
# Mac: Abre Docker Desktop desde Applications
# Verifica que el √≠cono de Docker aparezca en la barra superior
# Espera a que el √≠cono deje de estar animado

# Linux: Inicia el servicio
sudo systemctl start docker
```

### Error: "port is already allocated"

**Problema**: El puerto 8501 ya est√° en uso.

**Soluci√≥n 1**: Det√©n la aplicaci√≥n que est√° usando el puerto.
```bash
# Mac/Linux: Encontrar proceso usando el puerto
lsof -i :8501
kill -9 <PID>
```

**Soluci√≥n 2**: Usa un puerto diferente.
```bash
docker run -p 8502:8501 --env-file .env wind-forecast-app
# Accede en: http://localhost:8502
```

### Error: "invalid API key"

**Problema**: La API key de OpenAI no es v√°lida.

**Soluci√≥n**:
- Verifica que tu API key sea correcta en [OpenAI Platform](https://platform.openai.com/api-keys)
- Aseg√∫rate de que comience con `sk-`
- Revisa que no haya espacios extras en el archivo `.env`

### La imagen es muy grande

**Soluci√≥n**: La imagen usa `python:3.11-slim` que ya es optimizada. Si necesitas reducir m√°s:
```bash
# Usar alpine (m√°s peque√±o pero puede tener problemas de compatibilidad)
# Modificar la primera l√≠nea del Dockerfile:
FROM python:3.11-alpine
```

## üöÄ Uso R√°pido (Resumen)

### Opci√≥n 1: Con Docker (Recomendado para producci√≥n)

```bash
# 1. Construir la imagen
docker build -t wind-forecast-app .

# 2. Ejecutar con tu API key
docker run -p 8501:8501 -e OPENAI_API_KEY=tu-api-key wind-forecast-app

# 3. Abrir en el navegador
# http://localhost:8501
```

### Opci√≥n 2: Sin Docker (Desarrollo local)

```bash
# 1. Instalar dependencias
pip install -r requirements.txt

# 2. Configurar variables de entorno
cp .env.example .env
# Editar .env con tu OPENAI_API_KEY

# 3. Ejecutar la aplicaci√≥n
streamlit run app_streamlit.py
```

## ‚öôÔ∏è Caracter√≠sticas

- **Selecci√≥n de Modelo**: Elige entre diferentes modelos de OpenAI (GPT-3.5, GPT-4, GPT-4-turbo)
- **Control de Temperatura**: Ajusta la creatividad de las respuestas (0.0-1.0)
- **Historial de Chat**: Mantiene el contexto de la conversaci√≥n
- **Interfaz Moderna**: UI limpia y responsiva con Streamlit

## üê≥ Detalles del Dockerfile

```dockerfile
FROM python:3.11-slim          # Imagen base ligera
WORKDIR /app                   # Directorio de trabajo
COPY requirements.txt .        # Copiar dependencias
RUN pip install --no-cache-dir # Instalar sin cache
COPY app_streamlit.py .        # Copiar c√≥digo
EXPOSE 8501                    # Puerto de Streamlit
CMD ["streamlit", "run", ...]  # Comando de inicio
```

## üîß Configuraci√≥n

### Variables de Entorno

- `OPENAI_API_KEY`: (Requerido) Tu API key de OpenAI

### Puertos

- **8501**: Puerto por defecto de Streamlit

### Modelos Disponibles

- `gpt-3.5-turbo`: R√°pido y econ√≥mico, ideal para la mayor√≠a de tareas
- `gpt-4`: Mayor capacidad de razonamiento y precisi√≥n
- `gpt-4-turbo-preview`: Versi√≥n mejorada de GPT-4 con ventana de contexto mayor

## üìù Notas

- El contenedor ejecuta Streamlit en modo servidor (`--server.address=0.0.0.0`)
- Incluye healthcheck para monitoreo en producci√≥n
- La imagen usa Python 3.11 slim para optimizar tama√±o
- `.dockerignore` excluye archivos innecesarios del build

## üéØ Casos de Uso

Este ejemplo es √∫til para:
- Desplegar chatbots con LLM en producci√≥n
- Prototipar interfaces conversacionales r√°pidamente
- Aprender integraci√≥n de Streamlit + Docker + LangChain + OpenAI
- Testing de aplicaciones antes de desplegar en la nube
- Baseline para comparar con modelos locales (Ollama, etc.)

## üí° Pr√≥ximos Pasos

Para extender este ejemplo puedes:
- Agregar memoria persistente con bases de datos
- Implementar RAG (Retrieval Augmented Generation)
- Integrar con tus modelos de pron√≥stico de viento
- A√±adir autenticaci√≥n de usuarios
- Implementar streaming de respuestas

## üìö Referencias

- [Streamlit Documentation](https://docs.streamlit.io/)
- [LangChain OpenAI Integration](https://python.langchain.com/docs/integrations/platforms/openai)
- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)
- [Docker Best Practices](https://docs.docker.com/develop/dev-best-practices/)

